{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63220385-7c6b-488d-a15a-f034438d1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import llm, utils, config\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "prompt_template = config.standardized_prompt_template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba49f5fd-a313-475c-bf0d-69b7c8aef1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = prompt_template.replace(\"News Title:\\n{TITLE}\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa672a1-bd0c-469e-a799-50720faede7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the title and content of a healthcare news article, analyze whether the claims align with plausible scenarios and whether the article maintains internal consistency. Check for misleading or unclear statements, and conclude whether the news is real or fake.\\n\\nNews Content:\\n{NEWS}\\nConclusion: '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ecee1e-a0a0-4d65-9474-17caec35cb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "claim\n",
       "real    1643\n",
       "fake     177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def map_labels(text):\n",
    "    if text == 0:\n",
    "        return 'fake'\n",
    "    return 'real'\n",
    "\n",
    "data = pd.read_csv(\"CoAID.csv\")[['text_clean',  'class']]\n",
    "data.rename(columns={'class': 'claim', 'text_clean':'news'}, inplace=True)\n",
    "\n",
    "data['claim'] =data['claim'].apply(map_labels)\n",
    "data['title'] = [\"  \" for _ in range(data.shape[0])]\n",
    "data['claim'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5924b9ee-6e2d-4fb1-8c50-47575883f5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_new_tokens = 10\n",
    "\n",
    "metadata = [\n",
    "    # [\"assets/sft-qwen-fakehealth\", llm.load_qwen_llm, 'FakeHealth', \"Qwen\", 4],\n",
    "    [\"assets/sft-qwen-recovery\", llm.load_qwen_llm, 'ReCOVery', \"Qwen\", 4],\n",
    "    \n",
    "    # [\"assets/sft-llama-fakehealth\", llm.load_llama_llm, 'FakeHealth', \"Llama3\", 4], \n",
    "    [\"assets/sft-llama-recovery\", llm.load_llama_llm, 'ReCOVery', \"Llama3\", 2], \n",
    "\n",
    "    # [\"assets/sft-falcon-fakehealth\", llm.load_falcon_llm, 'FakeHealth', \"Falcon\", 2],\n",
    "    [\"assets/sft-falcon-recovery\", llm.load_falcon_llm, 'ReCOVery', \"Falcon\", 2],\n",
    "    \n",
    "    # [\"assets/sft-phi-fakehealth\", llm.load_phi_llm, 'FakeHealth', \"Phi\", 1],\n",
    "    [\"assets/sft-phi-recovery\", llm.load_phi_llm, 'ReCOVery', \"Phi\", 1],\n",
    "    \n",
    "]\n",
    "for model_path, load_callback, dataset_name, model_name, per_device_train_batch_size in metadata:\n",
    "    for model_loss in ['sigmoid_bco']:\n",
    "        output_dir = f\"assets/rlhf-{model_name.lower()}-{dataset_name.lower()}-cpo-{model_loss.replace('_','-')}\"\n",
    "        tokenizer, model, llm_path = load_callback(llm_path=output_dir)\n",
    "        \n",
    "        def standard_prompting(test, tokenizer, model, prompt_template, batch_size=1, max_new_tokens=10):\n",
    "            test_data = llm.MISSINFODataset(tokenizer=tokenizer, df=test, prompt_template=prompt_template)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "            predicts, labels = llm.make_the_generation(model=model, tokenizer=tokenizer, max_length=512,\n",
    "                                                    data_loader=test_dataloader, max_new_tokens=max_new_tokens)\n",
    "            processed_predicts = utils.output_processor(predicts)\n",
    "            clf_report = utils.evaluation_report(y_true=labels, y_pred=processed_predicts)\n",
    "            return predicts, processed_predicts, clf_report\n",
    "\n",
    "        predicts, processed_predicts, clf_report = standard_prompting(test=data, \n",
    "                                                                     tokenizer=tokenizer, \n",
    "                                                                     model=model, \n",
    "                                                                     prompt_template=prompt_template)\n",
    "        report_dict = {\n",
    "            \"llm\": llm_path,\n",
    "            \"clf_report\": clf_report,\n",
    "            \"generations\": predicts,\n",
    "            \"processed_generations\": processed_predicts,\n",
    "        }\n",
    "\n",
    "        utils.write_json(data=report_dict, path=f\"results/{model_name}-CoAID-rlhf-cpo-{model_loss.replace('_','-')}.json\")\n",
    "        \n",
    "        del model\n",
    "        del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634f28ca-a7f6-40c4-ac78-634ffac072f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 10\n",
    "\n",
    "metadata = [\n",
    "    [\"assets/sft-qwen-fakehealth\", llm.load_qwen_llm, 'FakeHealth', \"Qwen\", 4],\n",
    "    # [\"assets/sft-qwen-recovery\", llm.load_qwen_llm, 'ReCOVery', \"Qwen\", 4],\n",
    "    \n",
    "    [\"assets/sft-llama-fakehealth\", llm.load_llama_llm, 'FakeHealth', \"Llama3\", 4], \n",
    "    # [\"assets/sft-llama-recovery\", llm.load_llama_llm, 'ReCOVery', \"Llama3\", 2], \n",
    "\n",
    "    [\"assets/sft-falcon-fakehealth\", llm.load_falcon_llm, 'FakeHealth', \"Falcon\", 2],\n",
    "    # [\"assets/sft-falcon-recovery\", llm.load_falcon_llm, 'ReCOVery', \"Falcon\", 2],\n",
    "    \n",
    "    [\"assets/sft-phi-fakehealth\", llm.load_phi_llm, 'FakeHealth', \"Phi\", 1],\n",
    "    # [\"assets/sft-phi-recovery\", llm.load_phi_llm, 'ReCOVery', \"Phi\", 1],\n",
    "    \n",
    "]\n",
    "for model_path, load_callback, dataset_name, model_name, per_device_train_batch_size in metadata:\n",
    "    for model_loss in ['sigmoid_bco']:\n",
    "        output_dir = f\"assets/rlhf-{model_name.lower()}-{dataset_name.lower()}-cpo-{model_loss.replace('_','-')}\"\n",
    "        tokenizer, model, llm_path = load_callback(llm_path=output_dir)\n",
    "        \n",
    "        def standard_prompting(test, tokenizer, model, prompt_template, batch_size=1, max_new_tokens=10):\n",
    "            test_data = llm.MISSINFODataset(tokenizer=tokenizer, df=test, prompt_template=prompt_template)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "            predicts, labels = llm.make_the_generation(model=model, tokenizer=tokenizer, max_length=512,\n",
    "                                                    data_loader=test_dataloader, max_new_tokens=max_new_tokens)\n",
    "            processed_predicts = utils.output_processor(predicts)\n",
    "            clf_report = utils.evaluation_report(y_true=labels, y_pred=processed_predicts)\n",
    "            return predicts, processed_predicts, clf_report\n",
    "\n",
    "        predicts, processed_predicts, clf_report = standard_prompting(test=data, \n",
    "                                                                     tokenizer=tokenizer, \n",
    "                                                                     model=model, \n",
    "                                                                     prompt_template=prompt_template)\n",
    "        report_dict = {\n",
    "            \"llm\": llm_path,\n",
    "            \"clf_report\": clf_report,\n",
    "            \"generations\": predicts,\n",
    "            \"processed_generations\": processed_predicts,\n",
    "        }\n",
    "\n",
    "        utils.write_json(data=report_dict, path=f\"results/{model_name}-FH-CoAID-rlhf-cpo-{model_loss.replace('_','-')}.json\")\n",
    "        \n",
    "        del model\n",
    "        del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233f0c1-090a-4694-b6ba-1165ad40e610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
